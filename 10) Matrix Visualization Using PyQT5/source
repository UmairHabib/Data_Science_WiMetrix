import sys, os
import sqlalchemy as db
import pandas as pd
from pandas import DataFrame
import datetime
import matplotlib.pyplot as plt
import json
import numpy as np
import math
import csv
import arrow
import itertools
from tkinter import *
from tkinter import ttk

import sys
from PyQt5.QtWidgets import QApplication, QMainWindow, QWidget, QTableWidget, QPushButton,QTableWidgetItem,QLabel,QLineEdit,QMessageBox

colors=[]
Interval = 26
timeOfDay=480
engine = db.create_engine("mssql+pyodbc://sa:123456@localhost/us2_spts?driver=SQL+Server+Native+Client+11.0")

def jsonWriter(fileName,dictionary):
    with open(fileName, 'w') as outfile:
        json.dump(dictionary, outfile)
def jsonReader(fileName):
    try:
        with open(fileName, 'r') as JSON:
            dictionary = json.load(JSON)
            return dictionary
    except:
        return {}

allQueries=jsonReader("query.json")


def allWorker():
    query = '''SELECT[workerID]
    FROM[us2_spts].[wim_spts].[workers]'''
    df = Query_Runner(query)
    return df
def allOrderGetter():
    query="SELECT  [orderID] FROM [us2_spts].[wim_spts].[orders]"
    df=Query_Runner(query)
    return df
def lineOps(orderno):
   query="Select operationAutoID, opsequence ,SMV from [us2_spts].[wim_spts].[stylebulletin] where orderid='"+orderno+"' ORDER BY opsequence"
   df=Query_Runner(query)
   df.set_index('operationAutoID', inplace=True)
   return df
def getAllProgress(orderno):
   query="SELECT * from [us2_spts].dbo.progresscomplete where orderid= '"+orderno +"'"
   df=Query_Runner(query)
   return df
def macIDgetter():
   query="SELECT  [macID],[machineID]   FROM [us2_spts].[wim_spts].[machines]"
   df=Query_Runner(query)
   return df

def lineDataGetter(worker,operationAutoID,startTime,endTime):
#   query1 = "select  time,p_time,operationAutoID,workerID,quantity,SMV from [us2_spts].[dbo].[previousData] where workerID = "+"'"+ worker+"'"+ " and operationAutoID= "+"'"+operationAutoID+"'"+" and  p_time >= " +"'"+startTime+"'" +" and  p_time <= "+ "'"+endTime+"'"+" order by time"
    query1=allQueries['lineDataGetter']
    query1=query1.replace("?", str(worker), 1)
    query1=query1.replace("?", str(operationAutoID), 1)
    query1=query1.replace("?", str(startTime), 1)
    query1=query1.replace("?", str(endTime), 1)
    df2 = Query_Runner(query1)

    return df2

def countGetter(workerID,operationAutoID,startTime,endTime):
#   query1 = "select  count(*) as 'count' from [us2_spts].[dbo].[progressComplete]  where workerID = " + "'" + workerID + "'" + " and operationAutoID= " + "'" + operationAutoID + "'" + " and  p_time >= " + "'" + startTime + "'" + " and  p_time <= " + "'" + endTime + "'"
    query1=allQueries['countGetter']
    query1=query1.replace("?", str(workerID), 1)
    query1=query1.replace("?", str(operationAutoID), 1)
    query1=query1.replace("?", str(startTime), 1)
    query1=query1.replace("?", str(endTime), 1)
    df2 = Query_Runner(query1)
    return df2['count']


def remainingDataGetter(worker,operationAutoID,startTime,endTime,previousValue):
#   query1 = "select  time,p_time,operationAutoID,workerID,quantity,SMV from [us2_spts].[dbo].[progressComplete] where time > CAST("+"'"+previousValue+"'"+" AS DATETIME2) and workerID = "+"'"+ worker+"'"+" and operationAutoID= "+"'"+operationAutoID+"'"+" and  p_time >= " +"'"+startTime+"'" +" and  p_time <= "+ "'"+endTime+"'"+ "  order by time"
    query1=allQueries['remainingDataGetter']
    query1=query1.replace("?", str(previousValue), 1)
    query1=query1.replace("?", str(worker), 1)
    query1=query1.replace("?", str(operationAutoID), 1)
    query1=query1.replace("?", str(startTime), 1)
    query1=query1.replace("?", str(endTime), 1)
    df2 = Query_Runner(query1)
    return df2


def ideal_Matrix_Data_Getter(orderno):
   query1 = '''select t1.orderID, bundleID, operationAutoID, opsequence, SMV * t2.quantity as SAM
   from cfl_spts.orders as t1
   inner join cfl_spts.cutreport as t2 on t1.orderID = t2.orderID
   inner join cfl_spts.stylebulletin as t3 on t2.orderID = t3.orderID
   where t1.orderID = ''' + orderno + '''
   order by t2.bundleID, t3.opsequence
   '''

   df2 = Query_Runner(query1)
   return df2
def hole_Matrix_Data_Getter(orderno):
    query1 = ''' SELECT  [time]
         ,[bundleID]
         ,[operationAutoID]
         ,[macID]
         ,[workerID]
         ,[SMV]
         ,quantity
         ,[SAM]
     FROM us2_spts.dbo.[progresscomplete]
     where orderID=''' + orderno + '''
     order by [time]'''
    df2 = Query_Runner(query1)
    return df2
def OperationAutoIDGetter(orderno):  # Sequence-wise all operation auto id of an order from style bulletin
   query1 = '''  SELECT operationAutoID as 'sortedOps', opsequence, styleID
       FROM [us2_spts].[wim_spts].[stylebulletin]
       where [orderID]=''' + orderno + ''' order by opsequence'''
   df2 = Query_Runner(query1)
   return df2
def allOperationAutoIDGetter():
 query="Select distinct operationautoid from [us2_spts].[wim_spts].stylebulletin"
 df= Query_Runner(query)
 return df["operationautoid"]
def fault_operation_getter():
   query=" SELECT* from [us2_spts].[traffic].[Temp]"
   return Query_Runner(query)
def Query_Runner(query):
   df = pd.read_sql_query(query, engine)
   return df

def MedianTaker(allOperationAutoID ,workerOpList, faultsFrame):
   actual={}
   ideal={}
   efficiency={}
   actualWMVAverage={}
   for index,each in enumerate(allOperationAutoID):
       x=workerOpList[workerOpList['operationAutoID']==each]
       y=faultsFrame[faultsFrame["operationAutoID"]==each]
       if(len(x)!=0):
           actual.update({each:(sum(x['timeDifference']))})
           ideal.update({each:(sum(x['SAM']))})
           actualWMVAverage.update({each:(sum(x['timeDifference'])/sum(x['quantity']))})
           if len(y)>0:
            efficiency = {key: np.array([ideal[key] - actual.get(key, "#"), y["numOfFaults"].iloc[0]]) for key in ideal.keys()}
           else:
            efficiency = {key: np.array([ideal[key] - actual.get(key, "#"), 0.0]) for key in
                             ideal.keys()}
   return efficiency,ideal,actual,actualWMVAverage
def workerMatrix(orderno, faultsFrame):
   print('Worker Matrix',orderno)
   df2=hole_Matrix_Data_Getter(orderno)
   df=OperationAutoIDGetter(orderno)
   workerEfficiency={}
   idealSam = {}
   actualSam = {}
   actualSamAverage={}
   workers=df2['workerID'].unique()
   for workerID in workers:
       df3=df2[df2['workerID'] == workerID]
       df3['timeDifference'] = differenceColumn(df3)
       Eff,ideal,actual,SamAverage=MedianTaker(df['sortedOps'].values ,df3,faultsFrame[faultsFrame["workerID"]==workerID])
       workerEfficiency.update({workerID:Eff})
       idealSam.update({workerID:ideal})
       actualSam.update({workerID:actual})
       actualSamAverage.update({workerID:SamAverage})
   return workerEfficiency,idealSam,actualSam,actualSamAverage

def efficiencyMatrix():
    workerFrame=allWorker()
    allOrderFrame=allOrderGetter()
    allOrderList=allOrderFrame["orderID"].values
    #allOrderList=['1120180661/8','1120180939/6','1120180940/6','1120180940/7','1120180940/8']
    allWorkerEfficiencies={}
    allIdealSam={}
    allActualSam={}
    actualSamAverage={}
    for key in workerFrame['workerID']:
        allWorkerEfficiencies.update({key:{}})
        allIdealSam.update({key:{}})
        allActualSam.update({key:{}})
        actualSamAverage.update({key:{}})
    alloperations=list(allOperationAutoIDGetter().values)
    alloperations.insert(0, "workerID")
    faultsFrame=fault_operation_getter()
    for order in allOrderList:
        orderno = "'" + str(order) + "'"
        efficiency,ideal,actual,AverageSam=workerMatrix(orderno, faultsFrame[faultsFrame["orderID"]==order])
        for each in efficiency.keys():
            if each in allWorkerEfficiencies.keys():                                                            #means that element is already added so we have to sum up
                allWorkerEfficiencies.update({each:{key: allWorkerEfficiencies[each].get(key, 0) + efficiency[each].get(key, 0)   #adding corresponding worker efficiency
                                         for key in set(allWorkerEfficiencies[each]) | set(efficiency[each])}})
                allIdealSam.update({each:{key: allIdealSam[each].get(key, 0) + ideal[each].get(key, 0)   #adding corresponding worker efficiency
                                         for key in set(allIdealSam[each]) | set(ideal[each])}})
                allActualSam.update({each:{key: allActualSam[each].get(key, 0) + actual[each].get(key, 0)   #adding corresponding worker efficiency
                                         for key in set(allActualSam[each]) | set(actual[each])}})
                actualSamAverage.update({each:{key: actualSamAverage[each].get(key, 0) + AverageSam[each].get(key, 0)   #adding corresponding worker efficiency
                                         for key in set(actualSamAverage[each]) | set(AverageSam[each])}})
            else:
                allWorkerEfficiencies.update({each:efficiency.get(each, 'Not Found')})    #adding worker efficiency in bigger adjacency list
                allIdealSam.update({each:ideal.get(each, 'Not Found')})
                allActualSam.update({each:actual.get(each, 'Not Found')})
                actualSamAverage.update({each: AverageSam.get(each, 'Not Found')})
    nestedDictToCsv(r'C:\Users\Lucky\Desktop\WiMetrix files\Ideal.csv',allIdealSam,alloperations)
    nestedDictToCsv(r'C:\Users\Lucky\Desktop\WiMetrix files\Actual.csv', allActualSam, alloperations)
    nestedDictToCsv(r'C:\Users\Lucky\Desktop\WiMetrix files\WorkerEfficiency.csv', allWorkerEfficiencies, alloperations)
    nestedDictToCsv(r'C:\Users\Lucky\Desktop\WiMetrix files\SamAverage.csv', actualSamAverage, alloperations)
def nestedDictToCsv(fileName,Dict,alloperations):
    with open(fileName, "w", newline ='') as f:
        w = csv.DictWriter(f, alloperations)
        w.writeheader()
        for key, val in (Dict.items()):
            row = {'workerID': key}
            row.update(val)
            w.writerow(row)
def operationConverter(refTable,x):
   arr = []
   opsequence = list(refTable["opsequence"])
   autoid = list(refTable["operationAutoID"])
   i = 0
   while i != len(autoid):
       j = i + 1
       arr1 = []
       arr1.append(autoid[i])
       while j != len(autoid) and opsequence[i] == opsequence[j]:
           arr1.append(autoid[j])
           j = j + 1
       i = j
       arr.append(arr1)
   i = 0
   j = 0
   arr3 = []
   arr4=[]
   while (j != len(x) and i != len(arr)):
       try:
           index = arr[i].index(x[j])
           arr3.append(x[j])
           j = j + 1

       except:
           i = i + 1
   return arr3,arr4
def lineBalancing(orderno):
   progressFrame=getAllProgress(orderno)
   progressFrame["opsequence"]=progressFrame["opsequence"].fillna(1)
   machineFrame=macIDgetter()
   opFrame=lineOps(orderno)
   mainFrame = pd.DataFrame(index=machineFrame["macID"].values, columns=opFrame["opsequence"].unique())
   opFrame["opsequence"] = opFrame["opsequence"].fillna(1)
   for row in machineFrame["macID"]:
      df=progressFrame[progressFrame['macID'] == row]
      #print(row, list(df['operationAutoID'].unique()))
      if len(df)!=0:
           x,sequence=operationConverter(opFrame, list(df['operationAutoID'].unique()))
           print(x,sequence)
           mainFrame.set_value(row,sequence[0],x)
           print(row,x)
def IdealBalance(orderno):
    opFrame= lineOps(orderno)
    #query="SELECT top 1 max([quantity]) as quantity from [us2_spts].[wim_spts].[cutreport] where orderid='" +orderno+"'group by bundleid order by max([quantity]) desc"
    #df=Query_Runner(query)
    #max=df["quantity"].values
    arr=[]
    for i in opFrame["SMV"].values :
        arr.append(i)#*max[0])
    CL= np.max(np.array(arr))            # Worst Cycle Time of assembly Line
    Tp= sum(arr)   #Total Processing Time
    n= len(opFrame)
    DL= ((n*CL - Tp)/(n*CL ))*100 # balance delay
    PL= 9*60/CL # production
    print('Production ',PL, Tp, n)
    print(DL)
    avgTimeTaken= Tp/n
    print(avgTimeTaken)
    return CL ,opFrame
def OptimizedBalance(orderno):
   actualSamAverage, allWorkerEfficiencies = efficiencyMatrix()
   maxVal, opFrame= IdealBalance(orderno)
   df2 = hole_Matrix_Data_Getter("'"+orderno+"'")
   LBRefTable=pd.DataFrame(index=df2["workerID"].unique(),columns=opFrame['operationAutoID'].values)
   for  op in  list(LBRefTable.columns):
       for index in list(df2["workerID"].unique()):
               try:
                   if(actualSamAverage[index][op]):
                        LBRefTable.set_value(index,op, maxVal- actualSamAverage[index][op])
               except:
                    continue
   print(LBRefTable)
   #LBRefTable.to_csv(r'C:\Users\LUCKY\Desktop\9) Nested Dictionaries for Worker Efficiencies\xyz.csv')
def machineCalculator(target, efficiency, availableTime, opFrame):
    arr=np.divide(np.divide(np.array([target*val for val in opFrame['SMV'].values]),availableTime),efficiency)
    machines=[]
    for index,val in enumerate(arr):
        if(val-int(val)>=0.2):
            machines.append(math.ceil(val))
        else:
            machines.append(math.floor(val))
    return machines

def findsubsets(setOfValues, size):    #return List of subsets with specific size n
    return list(map(list, itertools.combinations(setOfValues, size)))


def LineComputation(target,opFrame,HoleFrame,approachingValue,threshold,flag):
    opFrame['opsequence'].fillna(1, inplace=True) # Fill null entries in opsequence column as 1
    Line = pd.DataFrame(index= opFrame.index)# it will contain worker Ids... for mapping a worker to operation
    occupiedWorkers=[]
    for operation,row in opFrame.iterrows():
        op=str(operation)
        machinesOfOperation=row['Machine Quantity']
        if(flag==0):
            thresholdFrame = HoleFrame[HoleFrame[op].between(approachingValue - (approachingValue / threshold), approachingValue)]
        else:
            thresholdFrame = HoleFrame[HoleFrame[op].between(approachingValue, approachingValue +(approachingValue / threshold))]
        if not thresholdFrame.empty:
            thresholdFrame[op]=np.abs(approachingValue - np.array(thresholdFrame[op].values))
            sortedFrame = thresholdFrame.sort_values(by=op)
            arr=[]
            tempApproach=0
            takenMachines=0
            for workerID, value in sortedFrame.iterrows():
                if workerID not in occupiedWorkers:
                    if tempApproach<=target and takenMachines<=machinesOfOperation:
                        wmv = HoleFrame.loc[workerID,op]  # data from origional sam average frame
                        numberOfPieces=timeOfDay/math.ceil(wmv)
                        tempApproach=tempApproach+numberOfPieces
                        takenMachines = takenMachines+1
                        arr.append(workerID)
                        occupiedWorkers.append(workerID)
                    else:
                        break

                else:
                    print('best Same Worker Found again',workerID)

            Line.set_value(operation, 'WorkerID', arr)
        else:
            print('No worker Found in Threshold')
    return Line
def OptimizedTechnique(orderno):
   approachingValue, opFrame= IdealBalance(orderno)
   print("Approaching Value: ",approachingValue)
   #print('Enter Line Target : ')
   target=2500
   target=np.float(target)
   efficiency=0.8
   availableTime=timeOfDay
   opFrame['Machine Quantity']=machineCalculator(target, efficiency, availableTime, opFrame)
   actualSamFrame=pd.read_csv(r'C:\Users\Lucky\Desktop\WiMetrix files\SamAverage.csv', index_col=0)
   counter=4
   flag =0
   for i in range(1,9):
       if(i>=1 and i<=4):
            if counter==1:
                counter=4/3
            Line=LineComputation(target,opFrame,actualSamFrame,approachingValue,counter,0)
       else:
           if flag==0:
               counter=4
               flag=1
           if counter == 1:
                counter=4/3
           Line=LineComputation(target,opFrame,actualSamFrame,approachingValue,counter,1)
       print(Line)
       counter=counter-1

       print(Line)
   #LBRefTable.to_csv(r'C:\Users\LUCKY\Desktop\9) Nested Dictionaries for Worker Efficiencies\xyz.csv')


def operationWiseSubsetMaker(orderno):
    approachingValue, opFrame = IdealBalance(orderno)
    target = 2500
    target = np.float(target)
    efficiency = 0.8
    availableTime = timeOfDay
    opFrame['Machine Quantity'] = machineCalculator(target, efficiency, availableTime, opFrame)
    actualSamFrame = pd.read_csv(r'C:\Users\Lucky\Desktop\WiMetrix files\SamAverage.csv', index_col=0)
    operationAutoID=opFrame['operationAutoID'].values
    print(actualSamFrame)
    print(opFrame)
    operationWiseSubsets={}
    # fileopen = open('data.txt', 'w+')
    for each in operationAutoID:
        arrOfSets = []
        machinesOfOperation=opFrame[opFrame['operationAutoID']==each]['Machine Quantity'].values[0]
        print('operation', each,'Machines ',machinesOfOperation)
        # fileopen.write('operation: {}, Machines: {}\n\n'.format(each, machinesOfOperation))
        each = str(each)
        workersOfOperation=actualSamFrame[actualSamFrame[each].notnull()][each]
        for i in range(1,machinesOfOperation+1):
            arrOfSets=arrOfSets+findsubsets(set(workersOfOperation.index.values),i)
        operationWiseSubsets.update({each:arrOfSets})
        print("No of Workers: ",len(workersOfOperation),"Subset size ",len(operationWiseSubsets[each])," ",operationWiseSubsets[each])
        # fileopen.write('No of Workers: {}, Subset size: {} {}\n------------------------------\n\n'.
        #                format(len(workersOfOperation), len(operationWiseSubsets[each]),
        #                       operationWiseSubsets[each]))

    # fileopen.close()
    return operationWiseSubsets

def subsetComputation(dictOfSubsets):
    AverageSamFrame = pd.read_csv(r'C:\Users\Lucky\Desktop\WiMetrix files\SamAverage.csv', index_col=0)
    setWiseValues=[]
    for operation in dictOfSubsets.keys():
        sets=dictOfSubsets[operation]
        for eachSet in sets:  #OneD array of workers
            filteredFrame=AverageSamFrame[AverageSamFrame.index.isin(eachSet)]
            setWiseValues.append(max(filteredFrame[operation].values))
        sort=[x for _, x in sorted(zip(setWiseValues, sets))]
        dictOfSubsets.update({operation:sort})

    print(dictOfSubsets)

def timeConverter(currentTime,endTime):   #overtime is taken as SAM
   minDate = arrow.get(currentTime)
   maxDate = arrow.get(endTime)  # datetime.strptime(str(dates[-1]), date_format)
   delta = maxDate - minDate
   minutes=delta.seconds/60
   if(minutes>timeOfDay or delta.days>0 or delta.days<0):
       return -1   #for SAM
   else:
       return minutes
def differenceColumn(df):
   allTime=list(df['time'])
   piecePerMinute=[]
   timeDifference=[]
   for index in range(0,len(allTime)-1):
       minutes=timeConverter(allTime[index],allTime[index+1])
       if minutes==-1:
           if (len(timeDifference) > 2):   #more than 1 entries
               timeDifference.append(timeDifference[len(timeDifference) - 1])
               piecePerMinute.append(piecePerMinute[len(piecePerMinute) - 1])  # add last entry
           elif (len(allTime) == 1):   #has exactly 1 entry
               row = df.iloc[len(allTime) - 1]
               timeDifference.append(row['SMV'])  # if there exist only one element add smv
               piecePerMinute.append(row['SMV'])
           else:
               timeDifference.append(0)  # has no entry
               piecePerMinute.append(0)
       else:
           row = df.iloc[index]
           piecePerMinute.append(row['quantity']/minutes)   #PPM
           timeDifference.append(minutes)
   if(len(timeDifference)>1):
       timeDifference.append(timeDifference[len(timeDifference)-1])
       piecePerMinute.append(piecePerMinute[len(piecePerMinute)-1])  #add last entry
   elif (len(allTime)==1):
       row = df.iloc[len(allTime)-1]
       timeDifference.append(row['SMV'])     #if there exist only one element add smv
       piecePerMinute.append(row['SMV'])
   else: #has no entry
       timeDifference.append(0)  # if there exist only one element add smv
       piecePerMinute.append(0)
   return timeDifference,piecePerMinute

def valueTaker(operationAutoID, df2,minutes,previousTime):
    actual = {}
    ideal = {}
    efficiency = {}
    actualSamAverage = {}
    #actual.update({operationAutoID: (sum(df2['timeDifference']))})
    actual.update({operationAutoID: (sum(df2['timeDifference']) / sum(df2['quantity']))})
    ideal.update({operationAutoID: (sum(df2['SMV']))})
    numOfDifferentDays=len(np.unique(df2["time"].dt.strftime('%y-%m-%d')))
    adder=sum(df2['quantity'])
    actualSamAverage.update({previousTime: [str(adder/ (numOfDifferentDays*int(minutes))),str(adder)]})
    efficiency = {
    key: np.array([ideal[key] - actual.get(key, "#"), (actual.get(key, 0) / ideal[key]) * 100]) for key in
    ideal.keys()}
    return efficiency, ideal, actual, actualSamAverage



def TimeAnalysis(workers,timeFrame,operationAutoID,startTime, endTime):
    minTime = arrow.get(startTime, 'HH:mm:ss')
    maxTime = arrow.get(endTime, 'HH:mm:ss')
    maxTime=datetime.timedelta(hours=maxTime.time().hour, minutes=maxTime.time().minute,seconds=maxTime.time().second)
    workerEfficiency = {}
    idealSam = {}
    actualSam = {}
    actualSamAverage =jsonReader('previousComputation.json')
    for workerID in workers:
        Eff={operationAutoID:{}}
        ideal={operationAutoID:{}}
        actual={operationAutoID:{}}
        SamAverage={operationAutoID:{}}
        temporary={}
        counter=0
        count=0
        checker=0
        previousDate=datetime.datetime(2000,1,1,0,0,0,0)
        date=datetime.datetime(2000,1,1,0,0,0,0)
        previousTime = datetime.timedelta(hours=minTime.time().hour, minutes=minTime.time().minute,
                                          seconds=minTime.time().second)

        if actualSamAverage.get(workerID):                      #if data already exists
            if actualSamAverage[workerID].get(operationAutoID):
                counter=countGetter(workerID,operationAutoID,startTime,endTime)
                previousCounter = actualSamAverage[workerID][operationAutoID]
                previousDate=list(previousCounter)[-1]
                count=int(previousCounter[previousDate][1])
                if counter.values>count:
                    checker=1
                else:
                    continue


        while(previousTime<maxTime):  #must have same comparison time type
            pt=arrow.get(str(previousTime), 'H:mm:ss')
            nextTime = datetime.timedelta(hours=pt.time().hour, minutes=pt.time().minute,seconds=pt.time().second) + datetime.timedelta(minutes=int(timeFrame))

            if checker==0:
                if(nextTime<=maxTime):
                    df3 = lineDataGetter(workerID, operationAutoID, str(previousTime), str(nextTime))
                else:
                    df3 = lineDataGetter(workerID, operationAutoID, str(previousTime), str(maxTime))
            else:
                if (nextTime <= maxTime):
                    df3 = remainingDataGetter(workerID, operationAutoID,  str(previousTime), str(nextTime) ,previousDate)
                else:
                    df3 = remainingDataGetter(workerID, operationAutoID, str(previousTime), str(maxTime) ,previousDate)
            count = count + len(df3)
            if not df3.empty:
                maximumTime = max(df3['time'])
                if ( maximumTime> date):
                    date = maximumTime
                df3['timeDifference'],df3['PPM'] = differenceColumn(df3)
                Eff, ideal, actual, SamAverage = valueTaker(operationAutoID, df3,timeFrame,str(previousTime))
                temporary.update(SamAverage)
                workerEfficiency.update({workerID: Eff})
                idealSam.update({workerID: ideal})
                actualSam.update({workerID: actual})
            elif previousTime<maxTime:
                temporary.update({str(previousTime):['0.0','0.0']})
            previousTime=nextTime
        if (checker!=0):
            temporary.update({str(date):[str(counter.values[0]),str(count)]})
        else:
            temporary.update({str(date): [str(0), str(count)]})
        workerEfficiency.update({workerID: Eff})
        idealSam.update({workerID: ideal})
        actualSam.update({workerID: actual})
        actualSamAverage.update({workerID:{operationAutoID:temporary}})
    return actualSamAverage


def simulator(workers,timeFrame,operationAutoID,startTime,endTime):
    if int(timeFrame)%5!=0:
        print("Invalid TimeFrame, it should be in multiples of 5")
        return
    actualSamAverage=TimeAnalysis(workers, '5', operationAutoID, startTime, endTime)
    minTime = arrow.get(startTime, 'HH:mm:ss')
    maxTime = arrow.get(endTime, 'HH:mm:ss')
    maxTime = datetime.timedelta(hours=maxTime.time().hour, minutes=maxTime.time().minute,
                                 seconds=maxTime.time().second)
    totalPieces={}
    standardPieces={}
    mergeInterval=int(timeFrame)/5
    sumPieces=[]
    for workerID in workers:
        previousTime = datetime.timedelta(hours=minTime.time().hour, minutes=minTime.time().minute,
                                          seconds=minTime.time().second)
        mergeTime=previousTime
        temporary={}
        mergedPieces = {}
        sum=0.0
        num=0
        adder=0
        while(previousTime<maxTime):
            pt=arrow.get(str(previousTime), 'H:mm:ss')
            previousPieceinTimeFrame=actualSamAverage[workerID][operationAutoID][str(previousTime)]
            futurePiecesinTimeFrame=float(previousPieceinTimeFrame[0])*float(5)    #multiplying it with 5 due to standard of 5 minutes data
            adder=adder+futurePiecesinTimeFrame
            sum=sum+futurePiecesinTimeFrame
            temporary.update({str(previousTime):futurePiecesinTimeFrame})
            num=num+1
            nextTime = datetime.timedelta(hours=pt.time().hour, minutes=pt.time().minute,
                                          seconds=pt.time().second) + datetime.timedelta(minutes=int(5))
            previousTime = nextTime
            if num == mergeInterval:
                mergedPieces.update({str(mergeTime): adder})
                mergeTime=previousTime
                adder=0
                num=0
        if 540% int(timeFrame)!=0:
            mergedPieces.update({str(mergeTime): adder})
        totalPieces.update({workerID:{operationAutoID:mergedPieces}})
        standardPieces.update({workerID: {operationAutoID: temporary}})
        sumPieces.append(sum)

    jsonWriter('previousComputation.json', actualSamAverage)
    jsonWriter('simualtor.json',standardPieces)
    jsonWriter('merged.json', totalPieces)
    return actualSamAverage

class Window(QMainWindow):
    def __init__(self):
        super().__init__()

        self.initUI()


    def initUI(self):
        self.returnedTableWidget = self.makeTable(self)
        self.makeTextUI(self)
        self.makeBtn(self)
        self.setWindowTitle("WiMetrix Worker Efficiency Analysis")
        self.setGeometry(100, 100, 1366, 786)
        self.show()

    def makeTable(self,parent):
        self.tableMaker = QTableWidget(parent)
        self.tableMaker.setGeometry(50, 250, 1266, 450)
        return self.tableMaker

    def makeTextUI(self, parent):
        textBoxWidth=200
        textBoxHeight=40
        self.operationAutoID = QLabel(parent)
        self.timeInterval = QLabel(parent)
        self.startTime = QLabel(parent)
        self.endTime = QLabel(parent)


        self.operationAutoID.setText('Operation ID')
        self.operationAutoID.move(100, 40)
        self.operationAutoIDText = QLineEdit(parent)
        self.operationAutoIDText.move(250, 40)
        self.operationAutoIDText.setText("1110")
        self.operationAutoIDText.resize(textBoxWidth, textBoxHeight)


        self.timeInterval.setText('Time Interval')
        self.timeInterval.move(750, 40)
        self.timeIntervalText = QLineEdit(parent)
        self.timeIntervalText.move(900, 40)
        self.timeIntervalText.setText("10")
        self.timeIntervalText.resize(textBoxWidth, textBoxHeight)


        self.startTime.setText('Start Time')
        self.startTime.move(100, 120)
        self.startTimeText = QLineEdit(parent)
        self.startTimeText.move(250, 120)
        self.startTimeText.setText("08:00:00")
        self.startTimeText.resize(textBoxWidth, textBoxHeight)

        self.endTime.setText('End Time')
        self.endTime.move(750, 120)
        self.endTimeText = QLineEdit(parent)
        self.endTimeText.move(900, 120)
        self.endTimeText.setText("17:00:00")
        self.endTimeText.resize(textBoxWidth, textBoxHeight)



    def makeBtn(self, parent):
        self.EditData = QPushButton("Edit Data", parent)
        self.LoadData = QPushButton("Load Data", parent)
        self.EditData.move(1000, 750)
        self.LoadData.move(1200, 750)
        self.LoadData.clicked.connect(self.LoadDataAction)

    def LoadDataAction(self):
        self.textFieldChecker()
        operationAutoID=self.operationAutoIDText.text()
        w = allWorker()
        workers=w['workerID'].values
        simulator(workers, self.timeIntervalText.text(), operationAutoID, self.startTimeText.text(), self.endTimeText.text())
        mergedPieces = jsonReader('merged.json')
        workerKeys=list(mergedPieces.keys())
        cols = ['WorkerID']
        cols=cols+list(mergedPieces[workerKeys[0]][operationAutoID])
        self.tableMaker.setRowCount(len(workerKeys))
        self.tableMaker.setColumnCount(len(cols))
        self.tableMaker.setHorizontalHeaderLabels(cols)
        for rowNo,workerID in enumerate(workerKeys):
            self.tableMaker.insertRow(rowNo)
            for columnNo,column in enumerate(cols):
                if columnNo==0:
                    self.tableMaker.setItem(rowNo, columnNo, QTableWidgetItem(workerID))
                else:
                    self.tableMaker.setItem(rowNo, columnNo, QTableWidgetItem(str(mergedPieces[workerID][operationAutoID][column])))

    def textFieldChecker(self):
        if len(self.operationAutoIDText.text())==0 or len(self.timeIntervalText.text())==0 or len(self.startTimeText.text())==0 or len(self.endTimeText.text())==0:
            msg = QMessageBox()
            msg.setIcon(QMessageBox.Critical)
            msg.setText("Kindly Enter Complete Data")
            msg.setWindowTitle("Error")
            msg.exec_()
            return

try:
  #lineBalancing('1120180661/8')
  #IdealBalance('1120180661/8')
  #OptimizedBalance('1120180661/8')
  #efficiencyMatrix()
  #OptimizedTechnique('1120180661/8')
  #dictOfSubsets=operationWiseSubsetMaker('1120180661/8')
  #subsetComputation(dictOfSubsets)
  #simulation()
  #GUIWorkerAnalysis()
  app = QApplication(sys.argv)
  UserInterface = Window()
  sys.exit(app.exec_())

except Exception as e:
  print('Exception Occured ' + str(e))
  exc_type, exc_obj, exc_tb = sys.exc_info()
  fname = os.path.split(exc_tb.tb_frame.f_code.co_filename)[1]
  print(exc_type, fname, exc_tb.tb_lineno)



# select t2.*, t3.*
#  INTO [us2_spts].[traffic].[Temp]
#  from traffic.qualitylog as t1
#  inner join (
#   SELECT pC.workerID, max(qualityLogID) as qualityLogID,
#       [qualityFault_operationID]
#       ,sum([defectsNo]) as numOfFaults
#   FROM [us2_spts].[traffic].[qualitylog] as qL
#   LEFT JOIN us2_spts.dbo.[progresscomplete] as pC
#   ON qL.qualityFault_operationID = pC.styleID and qL.itemID=pC.itemID
#   where qL.qualityFaultID < 1000 and qL.rework = 0
#   group by workerID, [qualityFault_operationID]
# ) as t2 on t1.qualityLogID = t2.qualityLogID
# inner join wim_spts.stylebulletin as t3 on t1.qualityFault_operationID = t3.styleID
# where t2.workerID IS NOT NULL
#  --having qL.qualityFaultID < 1000
















